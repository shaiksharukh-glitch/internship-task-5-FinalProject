‚ÄúSIEM is like a control room for cybersecurity. It collects logs from many systems, detects suspicious patterns (like too many login failures), and alerts the Blue Team. We‚Äôll build a mini version using ELK Stack (Elasticsearch, Logstash, Kibana) to detect and visualize security incidents.‚Äù

SIEM = the control room that watches all the ‚ÄúCCTV footage‚Äù (logs) from your computers and network.

It detects suspicious activity (like someone trying too many passwords).

What is the ELK Stack? ELK stands for: ‚Ä¢ E ‚Üí Elasticsearch ‚Ä¢ L ‚Üí Logstash ‚Ä¢ K ‚Üí Kibana It‚Äôs an open-source log management and analysis platform developed by Elastic. Together, these three tools work like the heart and brain of a SIEM system. Let‚Äôs break them down one by one üëá

Elasticsearch (E) ‚Äî ‚ÄúThe Brain‚Äù ‚Ä¢ Think of Elasticsearch as a super-fast search engine for data. ‚Ä¢ It stores, indexes, and searches massive amounts of log data in real time. ‚Ä¢ Example: When your system generates a log saying ‚ÄúFailed login attempt on Server A‚Äù, Elasticsearch saves it and makes it quickly searchable. In SIEM: Elasticsearch is where all logs (from firewalls, servers, systems) are stored and queried to detect suspicious activities.
Logstash (L) ‚Äî ‚ÄúThe Collector and Cleaner‚Äù ‚Ä¢ Logstash is a data pipeline tool ‚Äî it collects logs from different sources (like firewalls, routers, or web servers), processes them (cleans, filters, and formats), and then sends them to Elasticsearch. ‚Ä¢ Think of it as the post office that receives messy letters (logs) and organizes them neatly before delivery. In SIEM: Logstash ensures that all log data (Windows logs, network logs, etc.) are in a consistent and readable format before analysis.
Kibana (K) ‚Äî ‚ÄúThe Eyes‚Äù ‚Ä¢ Kibana is the visual dashboard for ELK. ‚Ä¢ It helps you visualize logs stored in Elasticsearch using charts, graphs, and dashboards. ‚Ä¢ You can also search logs, create alerts, and monitor security trends visually. In SIEM: Security analysts use Kibana to detect anomalies, such as a sudden increase in failed logins or network traffic from an unknown IP.
How They Work Together Here‚Äôs a simple real-world flow

Your network devices (firewalls, servers, etc.) generate logs.
Logstash collects and processes those logs.
The cleaned logs are sent to Elasticsearch, which indexes and stores them.
Kibana reads from Elasticsearch and shows dashboards for analysis.
This combination (ELK Stack) acts as a basic SIEM system ‚Äî it collects, analyzes, visualizes, and alerts based on security events.

Real-Life Example

An attacker tries multiple failed logins to the admin portal.
Each failed attempt is logged by the web server (say, Apache or Nginx).
Logstash collects these logs.
Elasticsearch stores and indexes them.
Kibana dashboard suddenly shows a spike in failed logins from one IP.
The analyst sees this and sets up an alert rule ‚Äî ‚ÄúIf 5 failed logins in 1 minute ‚Üí Trigger alert.‚Äù
Next time it happens, the SIEM detects the attack in real-time and notifies the Blue Team. üí° This is how ELK Stack helps you detect, analyze, and respond to incidents ‚Äî the main goal of a SIEM.
SIEM as the control room where: ‚Ä¢ All those camera videos (logs) come together, ‚Ä¢ It automatically watches and says things like: o ‚ÄúSomeone is trying the door key 20 times ‚Äî possible thief!‚Äù o ‚ÄúFire alarm activated ‚Äî immediate check needed!‚Äù üí° So in computers: ‚Ä¢ CCTV = Logs (data recorded from servers, firewalls, etc.)

Objective:

The goal of this project was to set up a Security Information and Event Management (SIEM) system using the ELK Stack to collect, analyze, and visualize security logs. Additionally, an SSH brute-force attack was simulated to observe how real-time logs appear in Kibana, demonstrating log monitoring and incident detection.

Why build a Mini-SIEM? ‚Ä¢ Problem SIEM solves: Systems and devices produce huge amounts of logs (events). Humans can‚Äôt watch all logs in real time. SIEM centralizes logs, makes them searchable, visual, and creates alerts so defenders can detect and respond to security incidents quickly. ‚Ä¢ goal in the project: Build a small, demonstrable SIEM pipeline (log collection ‚Üí storage ‚Üí visualization ‚Üí alerting) and show a full incident response cycle (detect ‚Üí contain ‚Üí eradicate ‚Üí report). 2. Key concepts & vocabulary ‚Ä¢ Log / Event: A record generated by software/hardware describing an action or state (e.g., login attempt, HTTP request, system startup). ‚Ä¢ Source types: System logs (syslog), application logs, web server logs, authentication logs, firewall logs, IDS/IPS alerts, Windows Event Logs, container logs. ‚Ä¢ Normalization / Parsing: Converting raw log text into structured fields (timestamp, src_ip, user, event_type) so searches/alerts can work reliably. ‚Ä¢ Enrichment: Adding context to logs (e.g., geoip for IP addresses, asset owner, threat intelligence tags). ‚Ä¢ Indexing: Storing parsed logs in a fast searchable structure (in ELK, Elasticsearch indices). ‚Ä¢ Correlation: Combining multiple events across time/sources to find meaningful patterns (e.g., repeated failed logins + new user creation). ‚Ä¢ Alerting: Rules that trigger when conditions are met (e.g., >10 failed logins from same IP in 5 min). ‚Ä¢ Triage: Analyst‚Äôs initial assessment of an alert‚Äîpriority, false positive check. ‚Ä¢ Containment / Eradication / Recovery: Incident response steps to stop damage, remove the threat, and restore systems. ‚Ä¢ Playbook: A prescriptive set of steps for particular incident types (e.g., brute-force playbook). ‚Ä¢ Retention / Storage / GDPR/privacy concerns: How long logs are kept and privacy handling (PII removal). 3. Components of Mini-SIEM (ELK stack) ‚Ä¢ Elasticsearch o Purpose: Store and index logs; fast search & aggregation. o You query indices to find events and to power visualizations. ‚Ä¢ Logstash o Purpose: Pipeline to parse, filter, and transform logs before storing in Elasticsearch. o Can apply grok patterns, mutate fields, add tags, run geoip enrichment. ‚Ä¢ Kibana o Purpose: Web UI for searching logs, building visualizations/dashboards, and creating alerts (Kibana Alerting or Elastic Rules). o Used for interactive analysis and creating the dashboards you‚Äôll screenshot for the report. ‚Ä¢ Beats (Filebeat) o Purpose: Lightweight shipper installed on a host to forward logs to Logstash/Elasticsearch. o Filebeat modules exist for common log sources (nginx, system, mysql). ‚Ä¢ Optional: Elastic Agent o Unified agent replacing Beats in some setups (not required for MVP).

Step-by-Step Implementation Step 1: Environment Setup

Tools Used:

Kali Linux (as attacker and log source)

ELK Stack (Elasticsearch, Logstash, Kibana)

Filebeat (for log forwarding)

Purpose: To establish a local SIEM environment where all logs from the system (/var/log/auth.log, syslog) are collected and visualized in a centralized dashboard.

Step 2: Installing and Configuring Elasticsearch

Commands Used:

wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.10.0-amd64.deb sudo dpkg -i elasticsearch-8.10.0-amd64.deb sudo systemctl enable elasticsearch sudo systemctl start elasticsearch

Explanation:

Elasticsearch acts as the data storage and search engine of the ELK stack.

It stores all logs received from Logstash or Filebeat.

After starting the service, Elasticsearch runs on http://localhost:9200 .

Output: When accessed, it shows JSON output like:

{ "name" : "localhost", "cluster_name" : "elasticsearch", "cluster_uuid" : "1VfTdjh4TRG3I-5zmpMrxA", "version" : { "number" : "8.10.0" } }

This confirms that Elasticsearch is running properly.

Step 3: Installing and Configuring Kibana

Commands Used:

wget https://artifacts.elastic.co/downloads/kibana/kibana-8.10.0-amd64.deb sudo dpkg -i kibana-8.10.0-amd64.deb sudo systemctl enable kibana sudo systemctl start kibana

Explanation:

Kibana provides a web-based visualization interface for Elasticsearch data.

It helps in monitoring, analyzing trends, and detecting anomalies.

Access via browser: http://localhost:5601/.

Output: The welcome page appeared showing ‚ÄúAdd Data / Integrations‚Äù, confirming successful installation.

Step 4: Installing and Configuring Filebeat

Commands Used:

sudo apt install filebeat -y sudo filebeat modules enable system sudo systemctl enable filebeat sudo systemctl start filebeat

Configuration Edited:

sudo nano /etc/filebeat/filebeat.yml

Enabled:

output.elasticsearch: hosts: ["localhost:9200"]

Explanation:

Filebeat acts as a lightweight log shipper.

It collects system logs (like authentication, SSH logs) and sends them to Elasticsearch.

Output: Filebeat service started successfully, ready to forward logs.

Step 5: Verifying Logs in Kibana

Actions Performed:

Opened Kibana ‚Üí Discover

Created index pattern: filebeat-*

Observed live logs from /var/log/auth.log and /var/log/syslog.

Output: System activities like login attempts, process logs, and authentication messages were visible in real-time.

(Screenshot reference: the Discover page showing filebeat-* logs)

Step 6: Simulating a Security Attack (Brute Force)

Command Used:

ssh root@localhost

Entered wrong password multiple times to simulate failed SSH logins.

Explanation:

This generated failed login events in /var/log/auth.log.

Filebeat automatically captured these and sent them to Elasticsearch.

Output in Kibana:

Logs appeared showing ‚ÄúFailed password for root from 127.0.0.1‚Äù

The timestamp, user, and source IP were displayed in Kibana Discover.

(Screenshot reference: failed SSH attempt log entry)

Step 7: Visualizing and Detecting Attacks

Actions in Kibana Dashboard:

Created Dashboard ‚Üí Add Visualization

Added:

Count of failed SSH logins

Top IP addresses (attacking sources)

User login activity trends over time

Output: Visual graphs showed spikes in failed login attempts ‚Äî indicating a brute-force attempt.

Final Outcome

Successfully set up the ELK-based Mini SIEM

Logs collected and visualized in real-time

SSH attack detected through Filebeat and Kibana

Dashboard created showing attack metrics
